# CleanSheet V1 Synthetic Eval — Summary
**Round:** 20260224.01 | **Copy version:** V1 | **n=60** | **Date:** 2026-02-24

---

## Executive Summary

V1 copy has the right pain points. It has the wrong persona. Every bucket — from the Excel operator to the skeptical quant methodologist — rejected the product's identity, not its premise. The "Receipt" line is the most resonant phrase in the copy by a factor of 2.5x, but it's buried between language that sounds like it was written for an academic bioinformatics lab. The fix is not more copy — it's a positioning edit.

**No persona converted. This is the right result to see in round one.**

---

## Quantitative Scores

| Dimension | Overall | Best Bucket | Worst Bucket |
|---|---|---|---|
| resonance agree+ | 0% | ai_loop_prisoner (0%) | all tied at 0% |
| intent agree+ | 0% | — | — |
| conversion_confidence agree+ | 0% | — | — |
| dealbreakers | 98% (59/60) | ai_loop_prisoner 90% | 5 buckets at 100% |
| price: too_expensive | 58% | — | — |
| price: fair | 42% | — | — |
| transparency_trust (mean) | 1.9 / 5 | — | skeptical_quant 1.4 |
| manual_friction_relief: yes | 0% | — | — |
| manual_friction_relief: partial | 52% | budget_gatekeeper 100% | social_science 0% |

The 0% agree+ across all three core Likert dimensions and every bucket is a clean floor read. Zero noise to suppress.

---

## Strongest Lines (What Landed)

Ranked by selection frequency across 60 personas:

1. **[15x] "Every change has a 'Receipt.' We track every decision, edit, and calculation in a navigable history."**
   This line won by nearly 3:1 over anything else. The metaphor is concrete, the claim is specific, and it resolves a felt anxiety that every bucket shares. This is the actual hero headline.

2. **[6x] "Every automated fix is a suggestion that requires your sign-off."**
   Landed hardest with ai_loop_prisoner and ai_weary_old_school_analyst. Directly addresses the primary trust gap with automation.

3. **[5x] "If I am out for one week, nobody can run this workflow without breaking something."**
   Most resonant pain framing. Pulled from the social proof section — persona voices, which means it's copy functioning as testimonial.

4. **[5x] "AI gets me 70% there, then I lose a day trying to trust the last 30%."**
   Strong with ai_loop_prisoner. Specific, credible, anger-shaped.

5. **[5x] "In genomic research, you can't trust a black box. I need to see the code behind the curve."**
   Selected by skeptical_quant_methodologist personas almost exclusively. The specificity of the research context made it feel real.

6. **[3x] "I keep the whole process in my head, and that is the problem."**
   Compact, universal, and unusually honest for landing page copy.

---

## What Feels Off — Dominant Themes

**1. "Polyglot Logic Engine" and "Transparency Tax" — mentioned by ~55 of 60 personas.**
   The single biggest copy failure. Across every bucket, in almost every response. Verbatim quotes: *"sounds like AI invented these terms yesterday"*, *"marketing trying too hard to sound technical"*, *"not how anyone in my field talks"*, *"feature names invented by GPT-4."* These two phrases are actively destroying credibility. They signal "startup that doesn't know its users."

**2. The copy reads as AI-generated.**
   Nearly half of all personas — unprompted — described the copy as written by AI, ChatGPT, or "someone who watched a documentary about my job." This is the most damaging possible signal for a product trying to establish transparency as a core value. The copy is undermining the brand positioning it's trying to establish.

**3. Wrong audience signal in the social proof.**
   Genomic research, music lab, housing fund — the testimonials don't map to the target audience's self-concept. Duct_tape_analyst: *"I work in operations, not a research lab."* Social_science_thesis: *"I saw 'genomic research' and that was it."* The testimonials are working against the conversion.

**4. "Indestructible timeline of logic" — flagged as overwrought.**
   Ranked alongside "Polyglot Logic Engine" in negative language. The adjective "indestructible" reads as hyperbole rather than confidence.

---

## Objections by Bucket

### duct_tape_analyst
**Core objection:** Does this work with Excel?
All 10 personas flagged the same gap. The copy mentions Python, MATLAB, and R — none of which are in this bucket's toolset. Zero mention of Excel, VBA, Power Query, or Access. Dealbreaker for all 10: *"This is clearly built for academic researchers, not someone managing monthly reports."*

### ai_loop_prisoner
**Core objection:** Does this debug code or just organize it?
The loop persona is stuck validating AI-generated output. They want a tool that catches logic errors. The copy promises visual tracking — which they read as *another layer of abstraction*, not a solution. *"I'm already trapped validating AI code. This looks like it adds another layer I'd need to validate."*

### skeptical_quant_methodologist
**Core objection:** No methodology, no white paper, no technical specification.
The most consistently specific objections of any bucket. Every persona generated variations of: *"I cannot defend a method I don't understand."* Price was not cited as a factor — methodology was the only thing that mattered. All 10 received the lowest transparency_trust scores (1s and 2s).

### social_science_thesis_dreader
**Core objection:** This product is not for me.
All 10 personas concluded the product was built for computational researchers. SPSS, NVivo, Stata, and qualitative coding are not mentioned anywhere in the copy. No student pricing. *"$29/month is nearly 10% of my monthly stipend."* The word "scripts" alone disqualifies this bucket.

### budget_gatekeeper
**Core objection:** No implementation path, no compliance info, no pilot option.
This bucket's objections were procurement-shaped: security certifications, onboarding timelines, grant committee justification, integration with institutional systems. The copy offers none of this. *"I can't bring an unproven tool to my board without SOC 2 or at least a pilot program."* The institutional pricing jump ($149/mo → $2,500/yr) was flagged as confusing: is that cheaper? More expensive? What's included?

### ai_weary_old_school_analyst
**Core objection:** Prove it with a screenshot.
This bucket trusts rigor over pitch. They equate marketing language with red flags. Every form of "show don't tell" request appeared here: screenshots, technical documentation, concrete examples of what a Logic Block looks like when applied to real R or Python code. *"No screenshots, no technical specifics, no proof this isn't just another tool that will create more problems than it solves."*

---

## Custom Field Findings

### transparency_trust (1–5)
- **Mean: 1.9 / 5.** No persona scored above 2.
- The page promises to be the transparency layer for opaque work — while itself being entirely opaque. This is an irony the personas named explicitly: *"They claim to provide transparency but the entire landing page is vague abstraction."*
- The product's core brand promise is being violated by its own copy.

### manual_friction_relief (yes / partial / no)
- **yes: 0%.** Not a single persona felt the landing page resolved their manual friction concern.
- **partial: 52%.** Mostly budget_gatekeeper and ai_loop_prisoner — the pain framing resonated, but the solution description didn't land.
- **no: 48%.** All of social_science_thesis, most of skeptical_quant.
- This field directly measures whether the hero benefit is being communicated. 0% yes means the value prop is not landing even at the "I get it" level.

---

## Unanswered Questions (Recurring)

Every bucket generated these, independently:

1. **Does it work with Excel?** (duct_tape_analyst, budget_gatekeeper, social_science_thesis)
2. **Does it execute code or just organize it?** (ai_loop_prisoner, ai_weary, skeptical_quant)
3. **What does a Logic Block actually look like?** (ai_weary, ai_loop_prisoner)
4. **Is there a free trial?** (all buckets except skeptical_quant, who would still reject without methodology docs)
5. **Where is data stored? Who has access?** (ai_weary, budget_gatekeeper, skeptical_quant)
6. **What are the compliance/security certifications?** (budget_gatekeeper)
7. **How long does onboarding/migration take?** (duct_tape_analyst, budget_gatekeeper)

---

## Price Signal

| Bucket | Dominant read | Notes |
|---|---|---|
| duct_tape_analyst | Too expensive | $29 steep for an unproven Excel alternative |
| ai_loop_prisoner | Fair — but conditional | Would pay if validated; skeptical it will deliver |
| skeptical_quant | Irrelevant | Methodology not price is the gate |
| social_science_thesis | Too expensive | $29 is 10% of a monthly TA stipend; no student tier |
| budget_gatekeeper | Institutional tier confusing | "$149/mo team → $2,500/yr institution" math unclear; no pilot |
| ai_weary_old_school | Fair — but conditional | Would not pay until they see a real demo |

The price point is not fundamentally broken for most buckets. The problem is they can't evaluate value because the product hasn't been shown to them concretely. Price objections are downstream of credibility objections.

---

## Diagnosis

This is a **positioning crisis**, not a copy crisis.

The pain points are right. "Receipt," the week-you're-gone line, tribal knowledge — these land because they describe something real. But after identifying the pain, the copy then signals that the solution is for *someone else*: an academic data scientist who codes in Python, MATLAB, and R, reads genomics papers, and works in a research lab.

5 of 6 buckets don't identify as that person.

The copy is doing two incompatible things simultaneously:
1. **Universal pain framing** ("your workflows break when you leave") — works for everyone
2. **Specialist solution language** ("Polyglot Logic Engine," code-heavy testimonials, genomics examples) — works for nobody in this audience

---

## V2 Priorities

Ranked by frequency and severity of objections:

**P0 — Must fix before running V2:**
1. Kill or rename "Polyglot Logic Engine." Either plain-English it or make the name earn its keep with an explanation.
2. Kill "Transparency Tax." Nobody used this framing unprompted. It's invented jargon.
3. Add an explicit Excel + Google Sheets integration statement in the hero or How It Works. This unblocks the duct_tape_analyst immediately.
4. Replace or supplement testimonials with voices that match target buckets — an ops person, not just a genomics lab.

**P1 — High impact, do in V2:**
5. Make "Every change has a 'Receipt.'" the H1 or H2. It's the most resonant line in the copy by a significant margin.
6. Add a product screenshot or short-form demo. This is the #1 requested thing: *show it*.
7. Add a free trial or free tier mention. Currently the path is "waitlist" with no trial. Every bucket flagged this.
8. Clarify institutional pricing (X seats, what support is included, academic vs. commercial).

**P2 — Structural fixes for V3+:**
9. Add a "How It Works" technical page linked from the landing page, specifically for skeptical_quant.
10. Add student pricing for social_science_thesis_dreader. Even a mention of "free for students" would change the conversion math.
11. Add data security / compliance section (even brief) for budget_gatekeeper.
12. The "if you can use a search bar" objection dismissal was noted as condescending by budget_gatekeeper.

---

## What Not to Change

- The pain framing in the hero works. The opening premise that workflows break when key people leave — stay.
- The "Receipt" concept is the product's clearest differentiator. Lean harder into it, don't abandon it.
- The objection handling section structure is right. The content needs rewriting; the intent is correct.
- The 3-tier pricing structure is not the problem.

---

*Results file: `results_v1.json` | Charts: `charts_v1.html` | Eval schema: `eval_schema_v1.json`*
*Prompts frozen at: `v1_prompts.jsonl` | Model: claude-sonnet-4-5-20250929 | n=60*
